{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/3D6RhKzlws7K6Wy4TaJW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ancestor9/2023-fastapi/blob/main/Week06/SDK_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🔍 SDK vs API\n",
        "\n",
        "| 구분     | SDK                                | API                                             |\n",
        "|----------|-------------------------------------|--------------------------------------------------|\n",
        "| 정의     | 개발에 필요한 전체 도구 모음        | 서비스나 기능에 접근하는 인터페이스              |\n",
        "| 포함 요소 | API, 문서, 도구, 샘플코드 등        | 함수나 메서드들의 정의와 설명                    |\n",
        "| 예       | `openai` 패키지, `boto3`            | `GET /v1/models`, `POST /v1/chat/completions`   |\n"
      ],
      "metadata": {
        "id": "3_bmAODGqQad"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **openapi API**"
      ],
      "metadata": {
        "id": "0HEnk-6t97ub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "YOUR_API_KEY= userdata.get('openapi')\n",
        "YOUR_API_KEY[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fSm3LCoTnPNB",
        "outputId": "3caf3a32-4322-4448-e6d4-55396f566b36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sk-proj-Jl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxKao5OJnNn2",
        "outputId": "b8d5cd0d-0dbd-4cba-a6ae-7c9fc6b806ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'chatcmpl-BJqNgIxHfTyCLUqCLCNXkbGO1cCtC', 'object': 'chat.completion', 'created': 1744069284, 'model': 'gpt-4o-mini-2024-07-18', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'Hello! How can I assist you today?', 'refusal': None, 'annotations': []}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 9, 'completion_tokens': 10, 'total_tokens': 19, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'service_tier': 'default', 'system_fingerprint': 'fp_86d0290411'}\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {YOUR_API_KEY}\",\n",
        "    \"Content-Type\": \"application/json\",\n",
        "}\n",
        "\n",
        "data = {\n",
        "    \"model\": \"gpt-4o-mini\",\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}]\n",
        "}\n",
        "\n",
        "response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=data)\n",
        "print(response.json())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **groq API**"
      ],
      "metadata": {
        "id": "VY-q-n9-7pS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import requests\n",
        "\n",
        "groq_key = userdata.get('groq')\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {groq_key}\",\n",
        "    \"Content-Type\": \"application/json\",\n",
        "}\n",
        "\n",
        "data = {\n",
        "    \"messages\": [\n",
        "        {\"role\": \"user\", \"content\": \"Hello!\"}\n",
        "    ],\n",
        "    \"model\": \"llama3-8b-8192\",  # Using a supported model on Groq\n",
        "    \"temperature\": 0.7,\n",
        "    \"max_tokens\": 300\n",
        "}\n",
        "\n",
        "response = requests.post(\n",
        "    \"https://api.groq.com/openai/v1/chat/completions\",\n",
        "    headers=headers,\n",
        "    json=data\n",
        ")\n",
        "\n",
        "# Check for errors and print the response for debugging\n",
        "if response.status_code != 200:\n",
        "    print(f\"Error: {response.status_code}\")\n",
        "    print(response.json())  # Print the error response for details\n",
        "else:\n",
        "    print(response.json()['choices'][0]['message']['content'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNSF2wq27tnH",
        "outputId": "3a8ef646-dee5-47ce-fa7f-8f908c0a352b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! It's nice to meet you. Is there something I can help you with, or would you like to chat?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#### 📦 SDK 구성 요소\n",
        "\n",
        "| 구성 요소           | 설명                                                                 |\n",
        "|--------------------|----------------------------------------------------------------------|\n",
        "| ✅ 라이브러리(API) | 특정 기능을 사용할 수 있게 미리 만들어진 코드<br>예: `openai.ChatCompletion.create()` |\n",
        "| ✅ 문서(Docs)       | 어떻게 사용하는지 설명된 가이드                                          |\n",
        "| ✅ 예제 코드        | 빠르게 시작할 수 있도록 샘플 코드 제공                                  |\n",
        "| ✅ 도구             | CLI 툴, 디버깅 툴, 인증 도구 등 포함될 수 있음                            |"
      ],
      "metadata": {
        "id": "PZ65PzweqOxC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **OpenAI SDK**\n",
        "- OpenAI API를 Python에서 더 편하고 안전하게 사용할 수 있게 해주는 도구 세트\n",
        "> OpenAI Python SDK는 Python 코드로 ChatGPT, GPT-4, DALL·E, Whisper 등을 쉽게 사용할 수 있도록 도와주는 라이브러리 + 개발 도구 묶음\n",
        "- 복잡한 HTTP 요청 대신, 간단한 함수 호출로 모든 걸 처리 가능\n",
        "- 실무에서는 거의 무조건 SDK 사용\n",
        "\n",
        "#### 🔧 OpenAI Python SDK 구성 요소 정리\n",
        "\n",
        "| 구성 요소                        | 설명                                      |\n",
        "|----------------------------------|-------------------------------------------|\n",
        "| `openai.ChatCompletion.create()` | GPT-3.5 / GPT-4 API 호출                  |\n",
        "| `openai.Image.create()`          | DALL·E로 이미지 생성                      |\n",
        "| `openai.Audio.transcribe()`      | Whisper로 음성 → 텍스트 변환              |\n",
        "| `openai.FineTuning`              | 모델 파인튜닝 관련 기능                   |\n",
        "| 인증, 예외 처리, 응답 구조 처리 | 직접 짤 필요 없이 SDK가 알아서 처리해 줌 |\n",
        "\n"
      ],
      "metadata": {
        "id": "gSDjQhC9pWXc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **openapi SDK**"
      ],
      "metadata": {
        "id": "fPQOaM1m-Hze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=YOUR_API_KEY)\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"Hello!\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49Hg8hwfnfzJ",
        "outputId": "867345d3-1592-49d1-fb68-bedc93bd5f06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"WoW What's wrong with you!\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFRDlQqLo98v",
        "outputId": "52b7cf04-5304-427e-b42b-d9b9e71ee4f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It sounds like you might be feeling frustrated or surprised. Is there something specific on your mind that you'd like to talk about? I'm here to help!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **groq SDK**"
      ],
      "metadata": {
        "id": "cqN_YGdY8gp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import requests\n",
        "\n",
        "groq_key = userdata.get('groq')\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {groq_key}\",\n",
        "    \"Content-Type\": \"application/json\",\n",
        "}\n",
        "\n",
        "# Check available models first\n",
        "response = requests.get(\n",
        "    \"https://api.groq.com/openai/v1/models\",\n",
        "    headers=headers\n",
        ")\n",
        "\n",
        "if response.status_code == 200:\n",
        "    models = response.json()\n",
        "    print(\"Available models:\")\n",
        "    for model in models[\"data\"]:\n",
        "        print(f\"- {model['id']}\")\n",
        "else:\n",
        "    print(f\"Error listing models: {response.status_code}\")\n",
        "    print(response.json())\n",
        "\n",
        "# Then try with a valid model from the list\n",
        "data = {\n",
        "    \"messages\": [\n",
        "        {\"role\": \"user\", \"content\": \"안녕하세요?\"}\n",
        "    ],\n",
        "    \"model\": \"llama3-8b-8192\",  # Use a model from the available list\n",
        "    \"temperature\": 0.7,\n",
        "    \"max_tokens\": 300\n",
        "}\n",
        "\n",
        "response = requests.post(\n",
        "    \"https://api.groq.com/openai/v1/chat/completions\",\n",
        "    headers=headers,\n",
        "    json=data\n",
        ")\n",
        "\n",
        "if response.status_code != 200:\n",
        "    print(f\"Error: {response.status_code}\")\n",
        "    print(response.json())\n",
        "else:\n",
        "    print(response.json()['choices'][0]['message']['content'])\n",
        "\n"
      ],
      "metadata": {
        "id": "KlZ6z66upM3n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2c281ed-96b8-494f-842d-9edc34b4cde5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available models:\n",
            "- llama-3.2-11b-vision-preview\n",
            "- distil-whisper-large-v3-en\n",
            "- whisper-large-v3\n",
            "- qwen-2.5-32b\n",
            "- whisper-large-v3-turbo\n",
            "- llama-3.1-8b-instant\n",
            "- llama-guard-3-8b\n",
            "- llama-3.3-70b-versatile\n",
            "- llama3-70b-8192\n",
            "- playai-tts-arabic\n",
            "- llama-3.2-1b-preview\n",
            "- playai-tts\n",
            "- deepseek-r1-distill-qwen-32b\n",
            "- llama3-8b-8192\n",
            "- mistral-saba-24b\n",
            "- gemma2-9b-it\n",
            "- deepseek-r1-distill-llama-70b\n",
            "- llama-3.2-90b-vision-preview\n",
            "- allam-2-7b\n",
            "- llama-3.3-70b-specdec\n",
            "- meta-llama/llama-4-scout-17b-16e-instruct\n",
            "- llama-3.2-3b-preview\n",
            "- qwen-qwq-32b\n",
            "- qwen-2.5-coder-32b\n",
            "안녕하세요! 😊\n"
          ]
        }
      ]
    }
  ]
}